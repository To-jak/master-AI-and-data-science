{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copie de MatMult.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-nNUkW58qCTs",
        "colab_type": "text"
      },
      "source": [
        "# GPU Programming with CUDA: Matrix Product"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PsjF8VvmrKVO",
        "colab_type": "text"
      },
      "source": [
        "Execute the cells below to run the code in google colab environment."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IWUsiAohd0P6",
        "colab_type": "code",
        "outputId": "e124eafa-e54c-4a52-ca25-ea62a847eed3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "! pip install git+git://github.com/frehseg/nvcc4jupyter.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+git://github.com/frehseg/nvcc4jupyter.git\n",
            "  Cloning git://github.com/frehseg/nvcc4jupyter.git to /tmp/pip-req-build-5mzb2u6a\n",
            "  Running command git clone -q git://github.com/frehseg/nvcc4jupyter.git /tmp/pip-req-build-5mzb2u6a\n",
            "Building wheels for collected packages: NVCCPlugin\n",
            "  Building wheel for NVCCPlugin (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for NVCCPlugin: filename=NVCCPlugin-0.0.1-cp36-none-any.whl size=2095 sha256=9715c86de13763e929dca66d72699afafbbe30ca5515c2fbb978e1e27edc22f1\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-n4c3jyg7/wheels/a4/a5/24/17a2b61f9a725a10155cc6fca753aae28436921df21fa16114\n",
            "Successfully built NVCCPlugin\n",
            "Installing collected packages: NVCCPlugin\n",
            "Successfully installed NVCCPlugin-0.0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G1EMybILd1VU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%load_ext nvcc_plugin"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4o5o1uaXqQQn",
        "colab_type": "text"
      },
      "source": [
        "## Classic product version without shared memory  \n",
        "  \n",
        "In this naive version, we compute the product $C = A * B$ in global memory with the standard matrix multiplication algorithm.\n",
        "\n",
        "* Each thread calculates an element of C\n",
        "* Each thread accesses to a whole line of A and a whole column of B\n",
        "\n",
        "**Downsides of this method**:\n",
        "* The access to data is non-aligned and scattered\n",
        "* Pb of coalescing\n",
        "* Repeated data access  \n",
        "  \n",
        "## Shared memory version\n",
        "\n",
        "Optimization: we can divide the matrix in different tiles and compute the product tile after tile.\n",
        "\n",
        "With this, we have:\n",
        "\n",
        "* Cooperative loading of a data tile in shared memory with regular accesses to global memory + quick accesses once in shared memory.\n",
        "* Some synchronization points to ensure that the data of partial results computed by threads are correctly loaded.\n",
        "\n",
        "## Version with cuBLAS\n",
        "  \n",
        "CUDA provides many libraries such as cuBLAS for linear algebra, which self-adapts to your hardware to achieve the best possible performance. We can use the cublasSgemm function to perform matrix multiplication."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qOmmgILtd1gT",
        "colab_type": "code",
        "outputId": "983cafc4-fd4c-4ea9-9a4d-077dbe5e6bbb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        }
      },
      "source": [
        "%%cu\n",
        "#include <stdlib.h>\n",
        "#include <stdio.h>\n",
        "\n",
        "#include <time.h>\n",
        "\n",
        "#include <cuda.h>\n",
        "#include <cuda_runtime.h>\n",
        "#include <helper_cuda.h>\n",
        "#include <cublas_v2.h>\n",
        "\n",
        "#define TILE_WIDTH 32\n",
        "#define SIZE 20\n",
        "\n",
        "\n",
        "/********************** CPU Version **************************/\n",
        "void CPUMatMul(float *A, float *B, float *C, int nb_ColA, int nb_ColB, int nb_RowA, int nb_RowB)\n",
        "{\n",
        "  for (int i = 0; i < nb_RowA; i++) {\n",
        "        for (int j = 0; j < nb_ColB; j++) {\n",
        "            int sum = 0;\n",
        "            for (int k = 0; k < nb_ColA; k++)\n",
        "                sum = sum + A[i * nb_ColA + k] * B[k * nb_ColB + j];\n",
        "            C[i * nb_ColB + j] = sum;\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "/********************** Classic Product Version **************************/\n",
        "__global__\n",
        "void classicMatMul(float *A, float *B, float *C, int nb_ColA, int nb_ColB, int nb_RowA, int nb_RowB)\n",
        "{\n",
        "  int row = blockIdx.y * blockDim.y + threadIdx.y;\n",
        "  int col = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "  if (row < nb_RowA && col < nb_RowB) {\n",
        "      for(int i = 0; i < nb_ColA; i++){\n",
        "          C[row * nb_ColB + col] += A[row * nb_ColA + i] * B[i * nb_ColB + col];\n",
        "      }\n",
        "  }\n",
        "}\n",
        "\n",
        "/********************** Shared Memory Version ****************************/\n",
        "__global__\n",
        "void sharedMemMatMul(float *A, float *B, float *C, int nb_ColA, int nb_ColB, int nb_RowA, int nb_RowB)\n",
        "{\n",
        "    int blockRow = blockIdx.y;\n",
        "    int blockCol = blockIdx.x;\n",
        "\n",
        "    // Matrix C Tile\n",
        "    float* Csub = &C[nb_ColB * TILE_WIDTH * blockRow + TILE_WIDTH * blockCol];\n",
        "\n",
        "    // value of C computed by one thread\n",
        "    float Cvalue = 0;\n",
        "\n",
        "    // Matrix C Tile Row & col\n",
        "    int row = threadIdx.y;\n",
        "    int col = threadIdx.x;\n",
        "\n",
        "    // We go through each tile of A and B that are\n",
        "    // required to compute the C tile\n",
        "    for (int m = 0; m < (nb_ColA / TILE_WIDTH); ++m) {\n",
        "\n",
        "        // A Tile\n",
        "        float* Asub = &A[nb_ColA * TILE_WIDTH * blockRow + TILE_WIDTH * m];\n",
        "\n",
        "        // B Tile\n",
        "        float* Bsub = &B[nb_ColB * TILE_WIDTH * m + TILE_WIDTH * blockCol];\n",
        "\n",
        "        // Shared memory for A & B tiles\n",
        "        __shared__ float As[TILE_WIDTH][TILE_WIDTH];\n",
        "        __shared__ float Bs[TILE_WIDTH][TILE_WIDTH];\n",
        "\n",
        "        // Load A & B values in shared memory with a thread\n",
        "        As[row][col] = Asub[row * nb_ColA + col];\n",
        "        Bs[row][col] = Bsub[row * nb_ColB + col];\n",
        "\n",
        "        // Synchronization before computing C\n",
        "        __syncthreads();\n",
        "        // Multiply Asub and Bsub together\n",
        "        for (int e = 0; e < TILE_WIDTH; ++e)\n",
        "            Cvalue += As[row][e] * Bs[e][col];\n",
        "\n",
        "        // Synch threads before other A & B tiles\n",
        "        __syncthreads();\n",
        "    }\n",
        "\n",
        "    // Write in C tile the cumulated value\n",
        "    Csub[row * nb_ColA + col] = Cvalue;\n",
        "}\n",
        "\n",
        "/********************** main **************************/\n",
        "int main(void)\n",
        "{\n",
        "  float *A, *B, *C, *gpu_A, *gpu_B, *gpu_C;\n",
        "  int nbRowA, nbRowB, nbColA, nbColB;\n",
        "\n",
        "  \n",
        "  nbRowA = TILE_WIDTH * SIZE;\n",
        "  nbRowB = TILE_WIDTH * SIZE;\n",
        "  nbColA = TILE_WIDTH * SIZE;\n",
        "  nbColB = TILE_WIDTH * SIZE;\n",
        "\n",
        "  A = (float*) malloc(nbRowA * nbColA * sizeof(float));\n",
        "  B = (float*) malloc(nbRowB * nbColB * sizeof(float));\n",
        "  C = (float*) malloc(nbRowA * nbColB * sizeof(float));\n",
        "\n",
        "  /* GPU space allocation */\n",
        "  cudaMalloc((void**) &gpu_A, nbRowA * nbColA * sizeof(float));\n",
        "  cudaMalloc((void**) &gpu_B, nbRowB * nbColB * sizeof(float));\n",
        "  cudaMalloc((void**) &gpu_C, nbRowA * nbColB * sizeof(float));\n",
        "\n",
        "  /* A & B initialization */\n",
        "  for (int i = 0; i < nbRowA * nbColA; i++) {\n",
        "    A[i] = 1.0;\n",
        "  }\n",
        "\n",
        "  for (int i = 0; i < nbRowB * nbColB; i++) {\n",
        "    B[i] = 2.0;\n",
        "  }\n",
        "\n",
        "  /* Copy of A & B on GPU */\n",
        "  cudaMemcpy(gpu_A, A, nbRowA * nbColA * sizeof(float), cudaMemcpyHostToDevice);\n",
        "  cudaMemcpy(gpu_B, B, nbRowB * nbColB * sizeof(float), cudaMemcpyHostToDevice);\n",
        "  cudaMemcpy(gpu_C, C, nbRowA * nbColB * sizeof(float), cudaMemcpyHostToDevice);\n",
        "\n",
        "\n",
        " dim3 threadsPerBlock (TILE_WIDTH, TILE_WIDTH);\n",
        " dim3 blocksPerGrid (nbRowA / threadsPerBlock.y, nbRowB / threadsPerBlock.x);\n",
        "\n",
        " double cpu_time = 0.0;\n",
        " float cpu_max_error = 0.0f;\n",
        " double classic_time = 0.0;\n",
        " float classic_max_error = 0.0f;\n",
        " double shared_mem_time = 0.0;\n",
        " float shared_mem_max_error = 0.0f;\n",
        " double cuBLAS_time = 0.0;\n",
        " float cuBLAS_max_error = 0.0f;\n",
        "\n",
        " int n_iter = 10;\n",
        " for(int i = 0; i < n_iter; i++){\n",
        "     \n",
        " /************ CPU **********************************/\n",
        " clock_t start = clock();\n",
        " CPUMatMul(A, B, C, nbColA, nbColB, nbRowA, nbRowB);\n",
        " clock_t end = clock();\n",
        " cpu_time += ((double) end-start)/CLOCKS_PER_SEC; // in seconds\n",
        " if(i == 0){\n",
        "    /* Vérification du résultat*/\n",
        "    for (int i = 0; i < nbRowA * nbColB; i++){\n",
        "        cpu_max_error = max(cpu_max_error, abs(C[i]- 2*nbRowB));\n",
        "    }\n",
        "  }\n",
        "\n",
        " /************ Classic Product Version **************/\n",
        " start = clock();\n",
        " classicMatMul<<<blocksPerGrid, threadsPerBlock>>>(gpu_A, gpu_B, gpu_C, nbColA, nbColB, nbRowA, nbRowB);\n",
        " end = clock();\n",
        " classic_time += ((double) end-start)/CLOCKS_PER_SEC; // in seconds\n",
        " if(i == 0){\n",
        "    cudaMemcpy(C, gpu_C, nbRowA * nbColB * sizeof(float), cudaMemcpyDeviceToHost);\n",
        "    /* Vérification du résultat*/\n",
        "    for (int i = 0; i < nbRowA * nbColB; i++){\n",
        "        classic_max_error = max(classic_max_error, abs(C[i]- 2*nbRowB));\n",
        "    }\n",
        "  }\n",
        "\n",
        " /************ Shared Memory Version ****************/\n",
        " start = clock();\n",
        " sharedMemMatMul<<<blocksPerGrid, threadsPerBlock>>>(gpu_A, gpu_B, gpu_C, nbColA, nbColB, nbRowA, nbRowB);\n",
        " end = clock();\n",
        " shared_mem_time += ((double) end-start)/CLOCKS_PER_SEC; // in seconds\n",
        " if(i == 0){\n",
        "    cudaMemcpy(C, gpu_C, nbRowA * nbColB * sizeof(float), cudaMemcpyDeviceToHost);\n",
        "    /* Vérification du résultat*/\n",
        "    for (int i = 0; i < nbRowA * nbColB; i++){\n",
        "        shared_mem_max_error = max(shared_mem_max_error, abs(C[i]- 2*nbRowB));\n",
        "    }\n",
        "  }\n",
        "\n",
        " /************ cuBLAS Version ******************/\n",
        " const float alf = 1;\n",
        " const float bet = 0;\n",
        " const float *alpha = &alf;\n",
        " const float *beta = &bet;\n",
        " \n",
        " // Create a handle for CUBLAS\n",
        " cublasHandle_t handle;\n",
        " cublasCreate(&handle);\n",
        " \n",
        " //warm up call\n",
        " cublasSgemm(handle, CUBLAS_OP_N, CUBLAS_OP_N, nbRowA, nbColB, nbColA, alpha, gpu_A, nbRowA, gpu_B, nbColA, beta, gpu_C, nbRowA);\n",
        "\n",
        " // Do the actual multiplication\n",
        " start = clock();\n",
        " cublasSgemm(handle, CUBLAS_OP_N, CUBLAS_OP_N, nbRowA, nbColB, nbColA, alpha, gpu_A, nbRowA, gpu_B, nbColA, beta, gpu_C, nbRowA);\n",
        " end = clock();\n",
        "\n",
        " // Destroy the handle\n",
        " cublasDestroy(handle);\n",
        "\n",
        " cuBLAS_time += ((double) end-start)/CLOCKS_PER_SEC; // in seconds\n",
        " if(i == 0){\n",
        "    cudaMemcpy(C, gpu_C, nbRowA * nbColB * sizeof(float), cudaMemcpyDeviceToHost);\n",
        "    /* Vérification du résultat*/\n",
        "    for (int i = 0; i < nbRowA * nbColB; i++){\n",
        "        cuBLAS_max_error = max(cuBLAS_max_error, abs(C[i]- 2*nbRowB));\n",
        "    }\n",
        "  }\n",
        " }\n",
        " \n",
        " printf(\"\\n************** CPU ************************\");\n",
        " printf(\"\\nCPU version took %f seconds to execute \\n\", cpu_time/n_iter);\n",
        " printf(\"Max error: %f\\n\", cpu_max_error);\n",
        " \n",
        " printf(\"\\n************** Classic Product ************\");\n",
        " printf(\"\\nClassic version took %f seconds to execute \\n\", classic_time/n_iter);\n",
        " printf(\"Max error: %f\\n\", classic_max_error);\n",
        "\n",
        " printf(\"\\n************** Shared Memory **************\");\n",
        " printf(\"\\nShared memory version took %f seconds to execute \\n\", shared_mem_time/n_iter);\n",
        " printf(\"Max error: %f\\n\", shared_mem_max_error);\n",
        "\n",
        " printf(\"\\n************** cuBLAS ****************\");\n",
        " printf(\"\\ncuBLAS version took %f seconds to execute \\n\", cuBLAS_time/n_iter);\n",
        " printf(\"Max error: %f\\n\", cuBLAS_max_error);\n",
        "\n",
        "  /* Libération de la mémoire sur le GPU*/ \n",
        "  cudaFree(gpu_A);\n",
        "  cudaFree(gpu_B);\n",
        "  cudaFree(gpu_C);\n",
        "\n",
        "  free(A);\n",
        "  free(B);\n",
        "  free(C);\n",
        " \n",
        " printf(\"\\n%s\\n\", cudaGetErrorString(cudaGetLastError()));\n",
        "}\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "************** CPU ************************\n",
            "CPU version took 1.746188 seconds to execute \n",
            "Max error: 0.000000\n",
            "\n",
            "************** Classic Product ************\n",
            "Classic version took 0.000044 seconds to execute \n",
            "Max error: 0.000000\n",
            "\n",
            "************** Shared Memory **************\n",
            "Shared memory version took 0.000009 seconds to execute \n",
            "Max error: 0.000000\n",
            "\n",
            "************** cuBLAS ****************\n",
            "cuBLAS version took 0.000005 seconds to execute \n",
            "Max error: 0.000000\n",
            "\n",
            "no error\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}